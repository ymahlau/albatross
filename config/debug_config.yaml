__module__: src.trainer.config
__name__: AlphaZeroTrainerConfig
data:
  collector_cfg:
    __module__: src.trainer.config
    __name__: CollectorConfig
    data:
      batch_size: 200
      buffer_size: 500
      log_every_sec: 20
      quick_start_buffer_path: null
      start_wait_n_samples: 500
      validation_percentage: 0.1
  compile_mode: reduce-overhead
  compile_model: false
  data_qsize: 10
  distributor_out_qsize: 10
  evaluator_cfg:
    __module__: src.trainer.config
    __name__: EvaluatorConfig
    data:
      enemy_cfgs:
      - __module__: src.agent.one_shot
        __name__: LegalRandomAgentConfig
        data:
          name: LegalRandomAgent
      - __module__: src.agent.search_agent
        __name__: AreaControlSearchAgentConfig
        data:
          deterministic: false
          name: AreaControlAgent
          search_cfg:
            __module__: src.search.config
            __name__: MCTSConfig
            data:
              backup_func_cfg:
                __module__: src.search.config
                __name__: StandardBackupConfig
                data: {}
              discount: 0.99
              eval_func_cfg:
                __module__: src.search.config
                __name__: AreaControlEvalConfig
                data:
                  health_threshold: 1.0
                  utility_norm:
                    __module__: src.game.values
                    __name__: UtilityNorm
                    value: NONE
              expansion_depth: 0
              extract_func_cfg:
                __module__: src.search.config
                __name__: StandardExtractConfig
                data: {}
              optimize_fully_explored: false
              sel_func_cfg:
                __module__: src.search.config
                __name__: DecoupledUCTSelectionConfig
                data:
                  exp_bonus: 1.414
              use_hot_start: true
      enemy_iterations: 100
      eval_rate_sec: 10
      num_episodes: 50
      prevent_draw: true
      temperature: 1
  game_cfg:
    __module__: src.game.battlesnake.battlesnake_conf
    __name__: BattleSnakeConfig
    data:
      all_actions_legal: true
      constrictor: false
      ec:
        __module__: src.game.battlesnake.battlesnake_enc
        __name__: SimpleBattleSnakeEncodingConfig
        data:
          centered: true
          compress_enemies: true
          fixed_food_spawn_chance: -1
          flatten: false
          include_area_control: false
          include_board: true
          include_current_food: true
          include_distance_map: false
          include_food_distance: false
          include_hazards: false
          include_next_food: false
          include_num_food_on_board: false
          include_number_of_turns: false
          include_snake_body: true
          include_snake_body_as_one_hot: false
          include_snake_head: true
          include_snake_health: false
          include_snake_length: false
          include_snake_tail: false
          include_tail_distance: false
          single_temperature_input: true
          temperature_input: false
      food_spawn_chance: 0
      h: 3
      hazard_damage: 14
      init_food_pos: []
      init_hazards: null
      init_snake_health:
      - 4
      - 4
      init_snake_len:
      - 3
      - 3
      init_snake_pos:
        0:
        - - 1
          - 0
        1:
        - - 2
          - 0
      init_snakes_alive: null
      init_turns_played: 0
      max_snake_health: null
      min_food: 0
      num_actions: 4
      num_players: 2
      reward_cfg:
        __module__: src.game.battlesnake.battlesnake_rewards
        __name__: StandardBattleSnakeRewardConfig
        data:
          living_reward: 0.0
          reward_type:
            __module__: src.game.battlesnake.battlesnake_rewards
            __name__: BattleSnakeRewardType
            value: STANDARD
          terminal_reward: 1.0
      royale: false
      shrink_n_turns: 25
      w: 3
      wrapped: false
  inf_cfg:
    __module__: src.trainer.config
    __name__: InferenceServerConfig
    data:
      statistics_every_sec: 60
      use_gpu: false
  info_qsize: 100
  init_new_network_params: false
  logger_cfg:
    __module__: src.trainer.config
    __name__: LoggerConfig
    data:
      buffer_gen: false
      id: 0
      name: null
      project_name: battlesnake_rl_test
      updater_bucket_size: 500
      wandb_mode: offline
      worker_episode_bucket_size: 50
  max_batch_size: 200
  max_cpu_evaluator: 1
  max_cpu_inference_server: 1
  max_cpu_log_dist_save_collect: 1
  max_cpu_updater: 1
  max_cpu_worker: 1
  max_eval_per_worker: 400
  net_cfg:
    __module__: src.network.resnet
    __name__: ResNetConfig3x3
    data:
      activation_type:
        __module__: src.network.utils
        __name__: ActivationType
        value: LEAKY_RELU
      eq_type:
        __module__: src.network.vision_net
        __name__: EquivarianceType
        value: NONE
      game_cfg: null
      layer_specs:
      - - 32
        - 1
        - 3
        - 0
        - 1
      lff_feature_expansion: 40
      lff_features: false
      norm_type:
        __module__: src.network.utils
        __name__: NormalizationType
        value: GROUP_NORM
      policy_head_cfg:
        __module__: src.network.fcn
        __name__: SmallHeadConfig
        data:
          activation_type:
            __module__: src.network.utils
            __name__: ActivationType
            value: LEAKY_RELU
          dropout_p: 0.2
          final_activation:
            __module__: src.network.utils
            __name__: ActivationType
            value: NONE
          hidden_size: 64
          normalization_type:
            __module__: src.network.utils
            __name__: NormalizationType
            value: GROUP_NORM
          num_layers: 2
      predict_policy: true
      value_head_cfg:
        __module__: src.network.fcn
        __name__: SmallHeadConfig
        data:
          activation_type:
            __module__: src.network.utils
            __name__: ActivationType
            value: LEAKY_RELU
          dropout_p: 0.2
          final_activation:
            __module__: src.network.utils
            __name__: ActivationType
            value: TANH
          hidden_size: 64
          normalization_type:
            __module__: src.network.utils
            __name__: NormalizationType
            value: GROUP_NORM
          num_layers: 2
  num_inference_server: 1
  num_worker: 1
  only_generate_buffer: false
  prev_run_dir: null
  prev_run_idx: null
  restrict_cpu: true
  save_state: false
  save_state_after_seconds: 30
  saver_cfg:
    __module__: src.trainer.config
    __name__: SaverConfig
    data:
      save_interval_sec: 30
  single_sbr_temperature: true
  temperature_input: false
  updater_cfg:
    __module__: src.trainer.config
    __name__: UpdaterConfig
    data:
      gradient_max_norm: 1.0
      mse_policy_loss: true
      optim_cfg:
        __module__: src.supervised.optim
        __name__: OptimizerConfig
        data:
          anneal_cfg:
            __module__: src.supervised.annealer
            __name__: TemperatureAnnealingConfig
            data:
              anneal_temps:
              - 0.001
              - 1.0e-05
              anneal_types:
              - __module__: src.supervised.annealer
                __name__: AnnealingType
                value: LINEAR
              - __module__: src.supervised.annealer
                __name__: AnnealingType
                value: COSINE
              cyclic: false
              end_times_min:
              - 1
              - 10
              init_temp: 0
          beta1: 0.9
          beta2: 0.99
          fused: false
          optim_type:
            __module__: src.supervised.optim
            __name__: OptimType
            value: ADAM_W
          weight_decay: 0.0001
      updates_until_distribution: 50
      use_gpu: false
      zero_sum_loss: true
  updater_in_qsize: 100
  updater_out_qsize: 10
  validator_data_qsize: 100
  worker_cfg:
    __module__: src.trainer.config
    __name__: WorkerConfig
    data:
      anneal_cfgs: null
      exploration_prob: 0.5
      max_game_length: 8
      max_random_start_steps: 0
      policy_eval_cfg:
        __module__: src.trainer.policy_eval
        __name__: PolicyEvalConfig
        data:
          eval_type:
            __module__: src.trainer.policy_eval
            __name__: PolicyEvalType
            value: TD_0
          lambda_val: 0.5
      prevent_draw: false
      quick_start: true
      search_cfg:
        __module__: src.search.config
        __name__: FixedDepthConfig
        data:
          average_eval: false
          backup_func_cfg:
            __module__: src.search.config
            __name__: LogitBackupConfig
            data:
              epsilon: 0
              hp_0: null
              hp_1: null
              init_random: true
              init_temperatures:
              - 10
              - 10
              num_iterations: 200
              sbr_mode:
                __module__: src.equilibria.logit
                __name__: SbrMode
                value: MSA
              use_cpp: true
          discount: 0.95
          eval_func_cfg:
            __module__: src.search.config
            __name__: InferenceServerEvalConfig
            data:
              active_wait_time: 0.05
              init_temperatures: null
              max_batch_size: 200
              max_clip_value: 1
              min_clip_value: -1
              policy_prediction: true
              random_symmetry: false
              single_temperature: true
              temperature_input: false
              utility_norm:
                __module__: src.game.values
                __name__: UtilityNorm
                value: NONE
          extract_func_cfg:
            __module__: src.search.config
            __name__: SpecialExtractConfig
            data:
              zero_sum_norm: false
      search_iterations: 1
      temperature: 1
      use_symmetries: true
hydra:
  run:
    dir: ./outputs/${now:%Y-%m-%d}/${now:%H-%M-%S}_None